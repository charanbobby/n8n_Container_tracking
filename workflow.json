{
  "name": "Container Tracking Automation",
  "nodes": [
    {
      "parameters": {
        "pollTimes": {
          "item": [
            {
              "mode": "everyMinute"
            }
          ]
        },
        "simple": false,
        "filters": {
          "sender": "sri.sunkara@silkandsnow.com"
        },
        "options": {
          "downloadAttachments": true
        }
      },
      "id": "b2f8e467-0702-4a03-a0ae-f54b126c23ce",
      "name": "Gmail Trigger",
      "type": "n8n-nodes-base.gmailTrigger",
      "typeVersion": 1,
      "position": [
        -768,
        112
      ],
      "webhookId": "gmail-trigger",
      "credentials": {
        "gmailOAuth2": {
          "id": "1",
          "name": "Gmail account"
        }
      }
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "jsCode": "// Split Gmail attachments into separate items\n// Gmail provides attachments as binary fields: attachment_0, attachment_1, attachment_2, etc.\nconst allItems = [];\n\n// Process all input items\nfor (const inputItem of $input.all()) {\n  const binary = inputItem.binary || {};\n  const json = inputItem.json || {};\n  \n  // Find all attachment binary fields\n  const attachmentKeys = Object.keys(binary).filter(key => key.startsWith('attachment_'));\n  \n  // If no attachment_ keys found, check if binary has 'data' key (from previous processing)\n  if (attachmentKeys.length === 0 && binary.data) {\n    // Already split, pass through\n    allItems.push({\n      json: json,\n      binary: binary\n    });\n  } else {\n    // Create one item per attachment\n    for (const key of attachmentKeys) {\n      const attachmentNum = key.replace('attachment_', '');\n      const attachmentData = binary[key];\n      \n      allItems.push({\n        json: {\n          ...json,\n          attachmentKey: key,\n          attachmentIndex: parseInt(attachmentNum),\n          filename: attachmentData.fileName || attachmentData.filename || `attachment_${attachmentNum}`,\n          mimeType: attachmentData.mimeType || attachmentData.mime || 'application/octet-stream',\n          fileExtension: attachmentData.fileExtension || (attachmentData.fileName ? attachmentData.fileName.split('.').pop() : '')\n        },\n        binary: {\n          data: attachmentData\n        }\n      });\n    }\n  }\n}\n\nreturn allItems;"
      },
      "id": "2237dcd5-ed2e-464f-a7b1-46b8aa613b02",
      "name": "Split Attachments",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -320,
        112
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "jsCode": "// Classify attachment by filename\nconst allItems = [];\nconst emailData = $('Gmail Trigger').item.json;\n\nfunction hasExt(name, ext) {\n  return name.toLowerCase().endsWith(ext.toLowerCase());\n}\n\nfunction containsWord(name, word) {\n  return new RegExp(`\\\\b${word}\\\\b`, 'i').test(name);\n}\n\nfor (const inputItem of $input.all()) {\n  const item = inputItem.json;\n  const binary = inputItem.binary || {};\n  const filenameRaw = item.filename || item.name || '';\n  const filename = filenameRaw.toLowerCase();\n\n  let attachmentType = 'unknown';\n\n  if ((containsWord(filename, 'bill') || containsWord(filename, 'bol')) && hasExt(filename, '.pdf')) {\n    attachmentType = 'bill';\n  } else if (containsWord(filename, 'ci') && hasExt(filename, '.xlsx')) {\n    attachmentType = 'commercial_invoice';\n  } else if (\n    (containsWord(filename, 'pkl') || containsWord(filename, 'pack') || containsWord(filename, 'packing')) &&\n    hasExt(filename, '.xlsx')\n  ) {\n    attachmentType = 'packaging_list';\n  }\n\n  allItems.push({\n    json: {\n      ...item,\n      attachmentType,\n      filename: filenameRaw,\n      emailSubject: emailData.subject || '',\n      emailDate: emailData.date || '',\n      emailFrom: emailData.from || emailData.sender || ''\n    },\n    binary,\n  });\n}\n\nreturn allItems;"
      },
      "id": "9484a2cf-072b-47cd-b603-04b200039386",
      "name": "Classify Attachment",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -96,
        112
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "jsCode": "// Prepare attachment data for processing\n// Pass through all items as-is, ensuring binary is properly structured\nconst allItems = [];\n\nfor (const inputItem of $input.all()) {\n  allItems.push({\n    json: inputItem.json,\n    binary: inputItem.binary || {}\n  });\n}\n\nreturn allItems;"
      },
      "id": "9570d62d-024c-444f-9e3a-82828bb126ef",
      "name": "Prepare Attachment",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        128,
        112
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict",
            "version": 1
          },
          "conditions": [
            {
              "id": "18a0ddd0-d562-498b-bf4e-6ad2d37a0685",
              "leftValue": "={{ $json.attachmentType }}",
              "rightValue": "bill",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "689b1acf-7bd2-46d6-8715-657401f82bea",
      "name": "Route by Type",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        352,
        112
      ]
    },
    {
      "parameters": {
        "model": "openai/gpt-4o",
        "options": {}
      },
      "id": "49bf24d6-5795-41dc-be8c-18d11082f91f",
      "name": "OpenRouter Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        600,
        16
      ],
      "credentials": {
        "openRouterApi": {
          "id": "1",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "model": "openai/gpt-4o",
        "options": {}
      },
      "id": "ed5c218e-bde8-4f0c-bb03-cd8d59adf2a5",
      "name": "OpenRouter Chat Model1",
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        600,
        208
      ],
      "credentials": {
        "openRouterApi": {
          "id": "1",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "operation": "pdf",
        "options": {
          "joinPages": true
        },
        "binaryPropertyName": "data"
      },
      "id": "efaa1145-5cf6-4327-ad81-8232e02de446",
      "name": "PDF to Text",
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        600,
        16
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForEachItem",
        "jsCode": "// Prepare bill data for LLM extraction\n// The PDF text should already be extracted in the 'text' field\nconst item = $input.item.json;\nconst binary = $input.item.binary || {};\n\n// Get text from extracted PDF\nconst textContent = item.text || '';\n\n// Create chatInput field that LLM Chain expects\nreturn {\n  json: {\n    ...item,\n    chatInput: textContent,\n    text: textContent\n  },\n  binary: binary\n};"
      },
      "id": "fa5a4e06-481d-4415-81a8-58dd1a92381a",
      "name": "Prepare Bill Data",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        800,
        16
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chatInput || $json.text || '' }}",
        "messages": {
          "messageValues": [
            {
              "id": "system",
              "message": "You are an expert at extracting container numbers from shipping documents. Extract all container numbers from the provided text. Container numbers typically follow formats like ABCD1234567 or ABCD 123456 7. Return ONLY a JSON object with a 'container_numbers' array of strings."
            },
            {
              "id": "user",
              "message": "={{ $json.chatInput || $json.text || '' }}"
            }
          ]
        },
        "options": {
          "responseFormat": {
            "type": "json_object"
          }
        }
      },
      "id": "c14427bf-b39e-4204-b5ba-62bb3ee45cc6",
      "name": "Extract Container Numbers",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        1000,
        16
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "jsCode": "// Parse and aggregate all container numbers from LLM responses\nconst allContainers = [];\n\nfunction extractJson(text) {\n  if (!text) return null;\n\n  // Remove fenced code blocks\n  text = text.replace(/```json([\\s\\S]*?)```/gi, '$1').trim();\n\n  // If it doesn't start with {, try to slice first {...} block\n  if (!text.trim().startsWith('{')) {\n    const start = text.indexOf('{');\n    const end = text.lastIndexOf('}');\n    if (start !== -1 && end !== -1 && end > start) {\n      text = text.slice(start, end + 1);\n    }\n  }\n\n  try {\n    return JSON.parse(text);\n  } catch (e) {\n    return null;\n  }\n}\n\nfor (const item of $input.all()) {\n  const text = item.json.text || item.json.response || '';\n  const parsed = extractJson(text);\n  if (!parsed) continue;\n\n  if (parsed.container_numbers && Array.isArray(parsed.container_numbers)) {\n    allContainers.push(...parsed.container_numbers);\n  }\n}\n\n// Remove duplicates and return single item with aggregated containers\nreturn [{\n  json: {\n    container_numbers: [...new Set(allContainers)]\n  }\n}];"
      },
      "id": "ac6bcce0-e29c-494d-ba4a-52b0fd7b129a",
      "name": "Parse Container Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1224,
        16
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": false,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "3bc3407e-5dc3-4591-92d2-5ee8fc63ae2b",
              "leftValue": "={{ $json.attachmentType }}",
              "rightValue": "packaging_list",
              "operator": {
                "type": "string",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "d9fb763f-0e4e-45e4-84a7-ae79321d9024",
      "name": "Filter PKL Only",
      "type": "n8n-nodes-base.filter",
      "typeVersion": 2,
      "position": [
        576,
        208
      ]
    },
    {
      "parameters": {
        "operation": "xlsx",
        "options": {
          "sheetName": "",
          "range": "",
          "headerRow": false
        },
        "binaryPropertyName": "data"
      },
      "id": "d75a91fa-5d15-4568-ab68-bbf1c349607c",
      "name": "Read XLSX",
      "type": "n8n-nodes-base.extractFromFile",
      "typeVersion": 1,
      "position": [
        600,
        208
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "jsCode": "// Generic PKL pre-processor.\n// ExtractFromFile gives one item per row as json.row (your sample).\n// We do NOT assume any fixed columns; we just send all rows as JSON.\n\nconst rows = $input.all()\n  .map(i => i.json.row || [])\n  .filter(r => Array.isArray(r) && r.length > 0);\n\n// chatInput is a JSON string with the array-of-rows.\nreturn [{\n  json: {\n    rows,\n    chatInput: JSON.stringify(rows)\n  }\n}];"
      },
      "id": "2e3995be-a72a-4f72-847d-28aa8c3c779b",
      "name": "Normalize PKL Grid",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        800,
        208
      ]
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.chatInput }}",
        "messages": {
          "messageValues": [
            {
              "id": "system",
              "message": "You read packing lists exported from Excel. You are given one sheet as a JSON array of rows. Each row is an array of cells in order: [cell_0, cell_1, ...]. Some rows are headers, some are product lines, some are totals.\n\nYour tasks:\n\n1. Identify which column is the SKU column (codes like SNSFNWO5006NR2, usually alphanumeric, stable per product line).\n2. Identify which column is the line quantity column (count of units for that SKU).\n   - Prefer columns whose header contains QTY or QUANTITY.\n   - Do not use weights, CBM, dimensions, or totals as quantity.\n3. For each product row with a SKU, output one object with:\n   - sku (string)\n   - qty_expected (number, quantity for that SKU on that row)\n4. If the sheet contains a \"Total\" row (cells like Total, TOTAL etc.), extract the document-level total quantity from the appropriate quantity column.\n5. Compute the sum of all your qty_expected values.\n6. Set checksum_ok = true if your sum equals the document-level total quantity (when present), otherwise false.\n\nReturn ONLY a JSON object with this shape:\n{\n  \"items\": [{\"sku\": \"SNSFNWO5006NR2\", \"qty_expected\": 82}, ...],\n  \"doc_total_qty_from_sheet\": 113,\n  \"qty_sum\": 113,\n  \"checksum_ok\": true\n}"
            },
            {
              "id": "user",
              "message": "=Here is the sheet as JSON array-of-rows:\n\n{{ $json.chatInput }}"
            }
          ]
        },
        "options": {
          "responseFormat": {
            "type": "json_object"
          }
        }
      },
      "id": "14f50ff3-e074-4e93-a662-52d37ef799a8",
      "name": "Extract SKU & Quantities",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.5,
      "position": [
        1000,
        208
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "jsCode": "// Parse PKL LLM JSON and enforce our own checksum.\n\nconst allItems = [];\nlet docTotalFromSheet = null;\nlet llmReportedSum = null;\nlet llmChecksumOk = null;\n\nfunction extractJson(text) {\n  if (!text) return null;\n  text = text.replace(/```json[\\s\\S]*?```/gi, m => m.replace(/```json|```/gi, '')).trim();\n  if (!text.trim().startsWith('{')) {\n    const start = text.indexOf('{');\n    const end = text.lastIndexOf('}');\n    if (start !== -1 && end !== -1 && end > start) {\n      text = text.slice(start, end + 1);\n    }\n  }\n  try {\n    return JSON.parse(text);\n  } catch (e) {\n    return null;\n  }\n}\n\nfor (const item of $input.all()) {\n  const text = item.json.text || item.json.response || '';\n  const parsed = extractJson(text);\n  if (!parsed) continue;\n\n  if (Array.isArray(parsed.items)) {\n    allItems.push(...parsed.items);\n  }\n  if (parsed.doc_total_qty_from_sheet != null) {\n    docTotalFromSheet = Number(parsed.doc_total_qty_from_sheet);\n  }\n  if (parsed.qty_sum != null) {\n    llmReportedSum = Number(parsed.qty_sum);\n  }\n  if (typeof parsed.checksum_ok === 'boolean') {\n    llmChecksumOk = parsed.checksum_ok;\n  }\n}\n\n// Recompute sum ourselves\nconst recomputedSum = allItems.reduce(\n  (acc, it) => acc + (Number(it.qty_expected) || 0),\n  0\n);\n\nlet checksumOk = null;\nif (Number.isFinite(docTotalFromSheet)) {\n  checksumOk = recomputedSum === docTotalFromSheet;\n}\n\nreturn [{\n  json: {\n    pkl_items: allItems,\n    qty_sum: recomputedSum,\n    doc_total_qty: docTotalFromSheet,\n    checksum_ok: checksumOk,\n    llm_reported_sum: llmReportedSum,\n    llm_checksum_ok: llmChecksumOk\n  }\n}];"
      },
      "id": "76c278ee-cfe1-4862-b8f6-c80fd70193d5",
      "name": "Parse PKL Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1224,
        208
      ]
    },
    {
      "parameters": {
        "mode": "runOnceForAllItems",
        "jsCode": "// Combine container numbers and PKL items from both parse nodes\n// This handles timing delays by waiting for all inputs\nlet containerNumbers = [];\nlet pklItems = [];\n\n// Process all input items - they may come from either parse node\nfor (const item of $input.all()) {\n  const json = item.json || {};\n  \n  // Check if this item has container_numbers (from Parse Container Response)\n  if (json.container_numbers && Array.isArray(json.container_numbers)) {\n    containerNumbers = json.container_numbers;\n  }\n  \n  // Check if this item has pkl_items (from Parse PKL Response)\n  if (json.pkl_items && Array.isArray(json.pkl_items)) {\n    pklItems = json.pkl_items;\n  }\n}\n\n// Return combined result\nreturn [{\n  json: {\n    container_numbers: containerNumbers,\n    pkl_items: pklItems\n  }\n}];"
      },
      "id": "94b67068-a393-4624-adf9-b2b0be7cc686",
      "name": "Merge Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1448,
        112
      ]
    },
    {
      "parameters": {
        "assignments": {
          "assignments": [
            {
              "id": "cf3bc389-2ba0-40cb-b6dd-1dd3f9a0fd17",
              "name": "container_numbers",
              "value": "={{ $json.container_numbers || [] }}",
              "type": "array"
            },
            {
              "id": "a2c34a7d-55dc-471c-b6bc-0be784d318f4",
              "name": "sku_items",
              "value": "={{ $json.pkl_items || [] }}",
              "type": "array"
            }
          ]
        },
        "options": {}
      },
      "id": "e75385fa-23d9-4a73-b95e-006ed274793f",
      "name": "Format Output",
      "type": "n8n-nodes-base.set",
      "typeVersion": 3.4,
      "position": [
        1672,
        112
      ]
    }
  ],
  "connections": {
    "Gmail Trigger": {
      "main": [
        [
          {
            "node": "Split Attachments",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Split Attachments": {
      "main": [
        [
          {
            "node": "Classify Attachment",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Classify Attachment": {
      "main": [
        [
          {
            "node": "Prepare Attachment",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Attachment": {
      "main": [
        [
          {
            "node": "Route by Type",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Route by Type": {
      "main": [
        [
          {
            "node": "PDF to Text",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Filter PKL Only",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Extract Container Numbers",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model1": {
      "ai_languageModel": [
        [
          {
            "node": "Extract SKU & Quantities",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "PDF to Text": {
      "main": [
        [
          {
            "node": "Prepare Bill Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Bill Data": {
      "main": [
        [
          {
            "node": "Extract Container Numbers",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Container Numbers": {
      "main": [
        [
          {
            "node": "Parse Container Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Container Response": {
      "main": [
        [
          {
            "node": "Merge Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Filter PKL Only": {
      "main": [
        [
          {
            "node": "Read XLSX",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Read XLSX": {
      "main": [
        [
          {
            "node": "Normalize PKL Grid",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Normalize PKL Grid": {
      "main": [
        [
          {
            "node": "Extract SKU & Quantities",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract SKU & Quantities": {
      "main": [
        [
          {
            "node": "Parse PKL Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse PKL Response": {
      "main": [
        [
          {
            "node": "Merge Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Results": {
      "main": [
        [
          {
            "node": "Format Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "pinData": {},
  "settings": {
    "executionOrder": "v1",
    "promptVersion": "2025-12-02-01"
  },
  "staticData": null,
  "tags": [],
  "triggerCount": 1,
  "updatedAt": "2025-12-03T13:30:38.374468",
  "versionId": "dd3d6719-12fb-4b6f-b8c2-b5ee9f47d634"
}